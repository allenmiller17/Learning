{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Facial Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the jpg file into a numpy array\n",
    "# image =face_recognition.load_image_file('people.jpg') # Sample Photo\n",
    "image =face_recognition.load_image_file('grad_photo.jpg') # Photo from graduation\n",
    "image =face_recognition.load_image_file('toni.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the faces in the image\n",
    "face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 face(s) in this photograph\n"
     ]
    }
   ],
   "source": [
    "number_of_faces = len(face_locations)\n",
    "print(f'I found {number_of_faces} face(s) in this photograph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A face is located at pixel location Top: 489, Left: 1157, Bottom: 712, Right: 1380\n",
      "A face is located at pixel location Top: 663, Left: 1603, Bottom: 885, Right: 1826\n",
      "A face is located at pixel location Top: 468, Left: 409, Bottom: 736, Right: 676\n"
     ]
    }
   ],
   "source": [
    "# Load the image into a Python Image Library object so that we can draw on top of it\n",
    "pil_image = PIL.Image.fromarray(image)\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image as a list of coordinates\n",
    "    top, right, bottom, left = face_location\n",
    "    print(f'A face is located at pixel location Top: {top}, Left: {left}, Bottom: {bottom}, Right: {right}')\n",
    "\n",
    "    # Let's draw a box around the face\n",
    "    draw = PIL.ImageDraw.Draw(pil_image)\n",
    "    draw.rectangle([left, top, right, bottom], outline='red')\n",
    "\n",
    "# Display the image on the screen\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Face Landmark Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the photo file into a numpy array\n",
    "#image =face_recognition.load_image_file('people.jpg') # Sample Photo\n",
    "image =face_recognition.load_image_file('grad_photo.jpg') # Photo from graduation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the face landmarks in the photo\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 3 face(s) in this photograph\n"
     ]
    }
   ],
   "source": [
    "number_of_faces = len(face_landmarks_list)\n",
    "print(f'I found {number_of_faces} face(s) in this photograph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image into a Python Image Library object so that we can draw on top of it\n",
    "pil_image = PIL.Image.fromarray(image)\n",
    "\n",
    "# Create a PIL drawing object to be able to draw lines later\n",
    "draw = PIL.ImageDraw.Draw(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chin in this face has the folling points: [(1122, 543), (1124, 577), (1127, 610), (1134, 641), (1149, 670), (1173, 693), (1204, 711), (1237, 723), (1267, 727), (1293, 719), (1315, 702), (1334, 681), (1347, 657), (1354, 631), (1357, 605), (1359, 578), (1361, 550)]\n",
      "The left_eyebrow in this face has the folling points: [(1166, 525), (1184, 512), (1207, 507), (1231, 508), (1252, 517)]\n",
      "The right_eyebrow in this face has the folling points: [(1295, 515), (1312, 509), (1330, 508), (1345, 513), (1353, 526)]\n",
      "The nose_bridge in this face has the folling points: [(1274, 542), (1276, 561), (1278, 580), (1281, 600)]\n",
      "The nose_tip in this face has the folling points: [(1249, 610), (1262, 614), (1275, 617), (1285, 615), (1294, 611)]\n",
      "The left_eye in this face has the folling points: [(1194, 546), (1209, 543), (1222, 543), (1236, 549), (1222, 550), (1208, 549)]\n",
      "The right_eye in this face has the folling points: [(1295, 550), (1308, 545), (1320, 545), (1331, 550), (1321, 552), (1308, 551)]\n",
      "The top_lip in this face has the folling points: [(1214, 641), (1236, 633), (1257, 632), (1271, 635), (1284, 633), (1297, 635), (1308, 641), (1303, 642), (1283, 637), (1270, 639), (1256, 637), (1219, 642)]\n",
      "The bottom_lip in this face has the folling points: [(1308, 641), (1296, 662), (1282, 672), (1268, 674), (1254, 673), (1233, 664), (1214, 641), (1219, 642), (1255, 660), (1269, 662), (1283, 659), (1303, 642)]\n",
      "The chin in this face has the folling points: [(1611, 752), (1613, 777), (1618, 801), (1624, 825), (1634, 847), (1648, 867), (1668, 884), (1692, 895), (1719, 899), (1744, 895), (1767, 884), (1787, 868), (1802, 849), (1812, 826), (1817, 801), (1821, 776), (1824, 750)]\n",
      "The left_eyebrow in this face has the folling points: [(1627, 720), (1640, 706), (1660, 701), (1680, 703), (1698, 710)]\n",
      "The right_eyebrow in this face has the folling points: [(1738, 708), (1756, 700), (1775, 698), (1794, 702), (1806, 715)]\n",
      "The nose_bridge in this face has the folling points: [(1716, 725), (1716, 742), (1716, 758), (1717, 776)]\n",
      "The nose_tip in this face has the folling points: [(1696, 790), (1706, 793), (1717, 796), (1728, 793), (1738, 790)]\n",
      "The left_eye in this face has the folling points: [(1647, 734), (1659, 726), (1672, 726), (1685, 734), (1672, 736), (1659, 736)]\n",
      "The right_eye in this face has the folling points: [(1746, 733), (1758, 724), (1772, 724), (1783, 732), (1772, 735), (1759, 734)]\n",
      "The top_lip in this face has the folling points: [(1672, 825), (1687, 813), (1704, 809), (1717, 811), (1731, 809), (1750, 813), (1766, 822), (1762, 822), (1731, 816), (1717, 818), (1704, 817), (1676, 824)]\n",
      "The bottom_lip in this face has the folling points: [(1766, 822), (1751, 842), (1733, 849), (1719, 850), (1705, 849), (1687, 842), (1672, 825), (1676, 824), (1705, 839), (1719, 841), (1733, 839), (1762, 822)]\n",
      "The chin in this face has the folling points: [(415, 563), (416, 597), (416, 630), (423, 663), (440, 692), (465, 715), (496, 734), (528, 750), (560, 754), (589, 747), (612, 729), (632, 705), (647, 678), (656, 649), (658, 619), (658, 591), (658, 563)]\n",
      "The left_eyebrow in this face has the folling points: [(458, 535), (474, 517), (498, 509), (523, 508), (546, 515)]\n",
      "The right_eyebrow in this face has the folling points: [(580, 515), (600, 510), (621, 512), (639, 520), (646, 539)]\n",
      "The nose_bridge in this face has the folling points: [(564, 533), (567, 552), (569, 571), (571, 592)]\n",
      "The nose_tip in this face has the folling points: [(535, 603), (551, 609), (566, 615), (580, 611), (592, 606)]\n",
      "The left_eye in this face has the folling points: [(484, 541), (498, 532), (512, 532), (527, 540), (513, 540), (499, 540)]\n",
      "The right_eye in this face has the folling points: [(585, 542), (600, 533), (613, 536), (624, 546), (612, 544), (599, 543)]\n",
      "The top_lip in this face has the folling points: [(503, 644), (528, 636), (550, 634), (564, 637), (579, 635), (595, 639), (610, 647), (603, 647), (579, 638), (564, 638), (550, 637), (510, 645)]\n",
      "The bottom_lip in this face has the folling points: [(610, 647), (594, 664), (578, 671), (563, 672), (548, 671), (527, 665), (503, 644), (510, 645), (549, 660), (563, 661), (578, 659), (603, 647)]\n"
     ]
    }
   ],
   "source": [
    "# Loop over each face\n",
    "for face_landmarks in face_landmarks_list:\n",
    "\n",
    "    # Loop over each facial feature (eye, nowe, mouth, lips, etc.)\n",
    "    for name, list_of_points in face_landmarks.items():\n",
    "\n",
    "        # Print the location of each facial feature in this image\n",
    "        print(f'The {name} in this face has the folling points: {list_of_points}')\n",
    "\n",
    "        # Trace out each facial feature in the image with a line\n",
    "        draw.line(list_of_points, fill='red', width=2)\n",
    "\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Face Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the photo file into a numpy array\n",
    "image =face_recognition.load_image_file('person.jpg') # Sample Photo\n",
    "#image =face_recognition.load_image_file('grad_photo.jpg') # Photo from graduation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Face Encodings\n",
    "face_encodings = face_recognition.face_encodings(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.20855837  0.01845226  0.05200073 -0.01912922 -0.02748854 -0.01855117\n",
      " -0.027255   -0.01845023  0.19835591 -0.01124563  0.19645655  0.01600665\n",
      " -0.15621799 -0.08862405 -0.00915151  0.11604425 -0.12597199 -0.14229293\n",
      " -0.03572801 -0.03505832  0.03726116  0.03980891 -0.07782653  0.07926028\n",
      " -0.14744216 -0.34706149 -0.10856137 -0.12216783  0.01723715 -0.11650674\n",
      "  0.06511289 -0.03900207 -0.18297048 -0.10930699  0.06847547  0.12637658\n",
      " -0.05037975 -0.09572256  0.13429828 -0.00703454 -0.16005868 -0.0557308\n",
      "  0.08435319  0.27441856  0.13435347  0.08523711  0.00496125 -0.11246422\n",
      "  0.16313241 -0.27373853  0.08402456  0.10128957  0.15344822  0.108321\n",
      "  0.11609212 -0.09201837  0.07474779  0.254884   -0.30816704  0.10207555\n",
      "  0.00198605 -0.01495524  0.03411678 -0.02620059  0.21705669  0.14441353\n",
      " -0.11093335 -0.12751675  0.17208098 -0.16183105 -0.04968167  0.12839431\n",
      " -0.03207513 -0.26411179 -0.31615093  0.07128873  0.36264002  0.18028145\n",
      " -0.13117109 -0.01013268 -0.05811105 -0.00737815  0.03560945  0.03457598\n",
      " -0.09948459 -0.06623539 -0.05779984 -0.01711861  0.24389154  0.12510221\n",
      "  0.003106    0.16942374 -0.01417198 -0.02782673  0.001431    0.06574464\n",
      " -0.10071306  0.00664665 -0.07640257 -0.06614345  0.03114731  0.03002048\n",
      "  0.07674068  0.13323891 -0.21063036  0.15302028 -0.0154896  -0.04833602\n",
      "  0.00523049 -0.02149037 -0.06463669  0.01915049  0.14195821 -0.29341784\n",
      "  0.22209316  0.12297856  0.04837456  0.15621082  0.00215635  0.00968098\n",
      " -0.03717988 -0.1172902  -0.17494754 -0.01424954  0.05999131 -0.07590403\n",
      "  0.0759552  -0.00694486]\n"
     ]
    }
   ],
   "source": [
    "if len(face_encodings) == 0:\n",
    "    # Now faces were found in the image.\n",
    "    print('No faces were found.')\n",
    "\n",
    "else:\n",
    "    # Grab the first face encoding\n",
    "    first_face_encoding = face_encodings[0]\n",
    "\n",
    "    # Print the results\n",
    "    print(first_face_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Face Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the known images\n",
    "image_of_person_1 = face_recognition.load_image_file(\"Recognition_Model_Pics//person_1.jpg\")\n",
    "image_of_person_2 = face_recognition.load_image_file(\"Recognition_Model_Pics//person_2.jpg\")\n",
    "image_of_person_3 = face_recognition.load_image_file(\"Recognition_Model_Pics//person_3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the face encoding of each person. This can fail if no one is found in the photo.\n",
    "person_1_face_encoding = face_recognition.face_encodings(image_of_person_1)[0]\n",
    "person_2_face_encoding = face_recognition.face_encodings(image_of_person_2)[0]\n",
    "person_3_face_encoding = face_recognition.face_encodings(image_of_person_3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all know face encodings\n",
    "known_face_encodings = [\n",
    "    person_1_face_encoding,\n",
    "    person_2_face_encoding,\n",
    "    person_3_face_encoding\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image we want to check and get the face encodings for any people in the picture\n",
    "unknown_image = face_recognition.load_image_file('Recognition_Model_Pics//unknown_7.jpg')\n",
    "\n",
    "face_locations = face_recognition.face_locations(unknown_image, number_of_times_to_upsample=2)\n",
    "unknown_face_encodings = face_recognition.face_encodings(unknown_image, known_face_locations=face_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Person 2 in the photo!\n"
     ]
    }
   ],
   "source": [
    "for unknown_face_encoding in unknown_face_encodings:\n",
    "\n",
    "    # Test if this unknown face encoding matches any of the three people we know\n",
    "    results = face_recognition.compare_faces(known_face_encodings, unknown_face_encoding)\n",
    "\n",
    "    name = 'Unknown'\n",
    "\n",
    "    if results[0]:\n",
    "        name = 'Person 1'\n",
    "    elif results[1]:\n",
    "        name = 'Person 2'\n",
    "    elif results [2]:\n",
    "        name = 'Person 3'\n",
    "\n",
    "    print(f'Found {name} in the photo!')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Digital Makeup to a Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the photo file into a numpy array\n",
    "image =face_recognition.load_image_file('test_image.jpg') # Sample Photo\n",
    "#image =face_recognition.load_image_file('grad_photo.jpg') # Photo from graduation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the face landmarks in the photo\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image into a Python Image Library object so that we can draw on top of it\n",
    "pil_image = PIL.Image.fromarray(image)\n",
    "\n",
    "# Create a PIL drawing object to be able to draw lines later\n",
    "d = PIL.ImageDraw.Draw(pil_image, 'RGBA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face_landmarks in face_landmarks_list:\n",
    "    # The face landmark detection model returns these features:\n",
    "    #   chin, left_eyebrow, right_eyebrow, nose_bridge, nose_tip, left_eye, right_eye, top_lip, bottom_lip\n",
    "\n",
    "    # Draw a line over the eyebrows\n",
    "    d.line(face_landmarks['left_eyebrow'], fill=(128,0,128,100), width=3)\n",
    "    d.line(face_landmarks['right_eyebrow'], fill=(128,0,128,100), width=3)\n",
    "\n",
    "\n",
    "    # Draw over the lips\n",
    "    d.polygon(face_landmarks['top_lip'], fill=(128,0,128,100))\n",
    "    d.polygon(face_landmarks['bottom_lip'], fill=(128,0,128,100))\n",
    "\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Lookalikes with Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image of the person we want to find similar people for\n",
    "#known_image = face_recognition.load_image_file(\"test_image.jpg\")\n",
    "known_image = face_recognition.load_image_file(\"grad_photo.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces found in image: 3\n"
     ]
    }
   ],
   "source": [
    "# Encode the known image\n",
    "face_locations = face_recognition.face_locations(known_image, number_of_times_to_upsample=2)\n",
    "\n",
    "face_encoding = face_recognition.face_encodings(known_image, known_face_locations=face_locations)\n",
    "\n",
    "if len(face_encoding) == 0:\n",
    "    # Now faces were found in the image.\n",
    "    print('No faces were found.')\n",
    "\n",
    "else:\n",
    "    print(f'Number of faces found in image: {len(face_encoding)}')\n",
    "    known_image_encoding = face_encoding[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to keep track of the most similar face match found\n",
    "best_face_distance = 1.0\n",
    "best_face_image = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all the images we want to check for similar people\n",
    "for image_path in Path('people').glob('*.png'):\n",
    "\n",
    "    # Load an image to check\n",
    "    unknown_image = face_recognition.load_image_file(image_path)\n",
    "\n",
    "    # Get the location of faces and face encodings for the current image\n",
    "    face_encodings = face_recognition.face_encodings(unknown_image)\n",
    "\n",
    "    # Get the face distance between the known person and all the faces in this image\n",
    "    face_distance = face_recognition.face_distance(face_encodings, known_image_encoding)[0]\n",
    "\n",
    "    # If this face is more similar to our known image than we've seen so far, save it\n",
    "    if face_distance < best_face_distance:\n",
    "        # Save the new best face distance\n",
    "        best_face_distance = face_distance\n",
    "\n",
    "        # Extract a copy of the actual face image itself so we can display it\n",
    "        best_face_image = unknown_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the face image that we fond to be the best match\n",
    "pil_image = PIL.Image.fromarray(best_face_image)\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = PIL.Image.fromarray(known_image_encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Deep_Learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "096db544af28c78b77f99f5b558907d77c58cb7acc42aa3ed5e25e2771f11f9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
