{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 14s 0us/step\n",
      "170508288/170498071 [==============================] - 14s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load Data Set\n",
    "(x_train, y_train), (x_test, y_test) =tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data in 0 - 1 range\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices \n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a model and add layers\n",
    "from tabnanny import verbose\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2))) # Good to put a MaxPooling layer after each block of Convolutional Layers\n",
    "model.add(tf.keras.layers.Dropout(0.25)) # Good to add after each MaxPooling layer\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))# Good to put a MaxPooling layer after each block of Convolutional Layers\n",
    "model.add(tf.keras.layers.Dropout(0.25))# Good to add after each MaxPooling layer\n",
    "\n",
    "model.add(tf.keras.layers.Flatten()) # Should flatten when transitioning from Convolutional Layer to Dense Layer\n",
    "\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.50)) # Good to add after a group of Dense Layers\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Add early stopping to the model\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, verbose=1)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer =  'adam',\n",
    "    metrics = ['accuracy'],\n",
    "    callbacks = [callback]    \n",
    ")\n",
    "\n",
    "# Print a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 52s 32ms/step - loss: 1.4939 - accuracy: 0.4548 - val_loss: 1.1188 - val_accuracy: 0.6004\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 1.1084 - accuracy: 0.6071 - val_loss: 0.9858 - val_accuracy: 0.6495\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.9634 - accuracy: 0.6614 - val_loss: 0.8369 - val_accuracy: 0.7067\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.8685 - accuracy: 0.6965 - val_loss: 0.8042 - val_accuracy: 0.7186\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.8006 - accuracy: 0.7187 - val_loss: 0.7446 - val_accuracy: 0.7395\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7593 - accuracy: 0.7347 - val_loss: 0.7009 - val_accuracy: 0.7608\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 57s 37ms/step - loss: 0.7175 - accuracy: 0.7483 - val_loss: 0.7131 - val_accuracy: 0.7526\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.6887 - accuracy: 0.7594 - val_loss: 0.6777 - val_accuracy: 0.7657\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6560 - accuracy: 0.7708 - val_loss: 0.6620 - val_accuracy: 0.7789\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6319 - accuracy: 0.7809 - val_loss: 0.6709 - val_accuracy: 0.7718\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.6134 - accuracy: 0.7861 - val_loss: 0.6400 - val_accuracy: 0.7789\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5914 - accuracy: 0.7935 - val_loss: 0.6419 - val_accuracy: 0.7788\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5775 - accuracy: 0.7978 - val_loss: 0.6452 - val_accuracy: 0.7826\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5690 - accuracy: 0.8015 - val_loss: 0.6252 - val_accuracy: 0.7926\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5490 - accuracy: 0.8104 - val_loss: 0.6434 - val_accuracy: 0.7846\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5391 - accuracy: 0.8130 - val_loss: 0.6434 - val_accuracy: 0.7883\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5182 - accuracy: 0.8164 - val_loss: 0.6558 - val_accuracy: 0.7865\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 41s 27ms/step - loss: 0.5086 - accuracy: 0.8218 - val_loss: 0.6546 - val_accuracy: 0.7807\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.5109 - accuracy: 0.8230 - val_loss: 0.6622 - val_accuracy: 0.7831\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.4970 - accuracy: 0.8255 - val_loss: 0.6469 - val_accuracy: 0.7894\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.4870 - accuracy: 0.8293 - val_loss: 0.6489 - val_accuracy: 0.7863\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4826 - accuracy: 0.8309 - val_loss: 0.6401 - val_accuracy: 0.7912\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4690 - accuracy: 0.8361 - val_loss: 0.6611 - val_accuracy: 0.7861\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4690 - accuracy: 0.8368 - val_loss: 0.6417 - val_accuracy: 0.7915\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4659 - accuracy: 0.8369 - val_loss: 0.6232 - val_accuracy: 0.7975\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4583 - accuracy: 0.8416 - val_loss: 0.6755 - val_accuracy: 0.7834\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4515 - accuracy: 0.8405 - val_loss: 0.6584 - val_accuracy: 0.7909\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4429 - accuracy: 0.8456 - val_loss: 0.6565 - val_accuracy: 0.7937\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.4373 - accuracy: 0.8470 - val_loss: 0.6583 - val_accuracy: 0.7958\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.4434 - accuracy: 0.8423 - val_loss: 0.6828 - val_accuracy: 0.7873\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'sample_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\allen\\source\\repos\\Learning\\NN_Image_Recognition\\Image_Recognition.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/allen/source/repos/Learning/NN_Image_Recognition/Image_Recognition.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m f\u001b[39m.\u001b[39mwrite_text(model_structure)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/allen/source/repos/Learning/NN_Image_Recognition/Image_Recognition.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Save neural network trained weights\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/allen/source/repos/Learning/NN_Image_Recognition/Image_Recognition.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39;49msample_weights(\u001b[39m'\u001b[39m\u001b[39mmodel_weights.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'sample_weights'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x_train, \n",
    "    y_train,\n",
    "    batch_size = 32,\n",
    "    epochs = 30,\n",
    "    validation_data = (x_test, y_test),\n",
    "    shuffle = True    \n",
    ")\n",
    "\n",
    "# Save neural network sturcture\n",
    "model_structure = model.to_json()\n",
    "f = Path('modlel_structure.json')\n",
    "f.write_text(model_structure)\n",
    "\n",
    "# Save neural network trained weights\n",
    "model.save_weights('model_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Deep_Learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "096db544af28c78b77f99f5b558907d77c58cb7acc42aa3ed5e25e2771f11f9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
