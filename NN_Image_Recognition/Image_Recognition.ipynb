{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data Set\n",
    "(x_train, y_train), (x_test, y_test) =tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data in 0 - 1 range\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices \n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a model and add layers\n",
    "from tabnanny import verbose\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2))) # Good to put a MaxPooling layer after each block of Convolutional Layers\n",
    "model.add(tf.keras.layers.Dropout(0.25)) # Good to add after each MaxPooling layer\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))# Good to put a MaxPooling layer after each block of Convolutional Layers\n",
    "model.add(tf.keras.layers.Dropout(0.25))# Good to add after each MaxPooling layer\n",
    "\n",
    "model.add(tf.keras.layers.Flatten()) # Should flatten when transitioning from Convolutional Layer to Dense Layer\n",
    "\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.50)) # Good to add after a group of Dense Layers\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Add early stopping to the model\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, verbose=1)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer =  'adam',\n",
    "    metrics = ['accuracy']    \n",
    ")\n",
    "\n",
    "# Print a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 45s 28ms/step - loss: 1.5215 - accuracy: 0.4444 - val_loss: 1.1638 - val_accuracy: 0.5875\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0927 - accuracy: 0.6114 - val_loss: 0.9034 - val_accuracy: 0.6875\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.9375 - accuracy: 0.6680 - val_loss: 0.8401 - val_accuracy: 0.7073\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.8547 - accuracy: 0.6998 - val_loss: 0.7471 - val_accuracy: 0.7398\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.7927 - accuracy: 0.7223 - val_loss: 0.7518 - val_accuracy: 0.7468\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.7465 - accuracy: 0.7369 - val_loss: 0.7320 - val_accuracy: 0.7439\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.7107 - accuracy: 0.7504 - val_loss: 0.7025 - val_accuracy: 0.7545\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6861 - accuracy: 0.7589 - val_loss: 0.6990 - val_accuracy: 0.7642\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6516 - accuracy: 0.7707 - val_loss: 0.6800 - val_accuracy: 0.7676\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6277 - accuracy: 0.7793 - val_loss: 0.6781 - val_accuracy: 0.7677\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.6098 - accuracy: 0.7868 - val_loss: 0.6527 - val_accuracy: 0.7780\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 43s 28ms/step - loss: 0.5891 - accuracy: 0.7928 - val_loss: 0.6682 - val_accuracy: 0.7720\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5777 - accuracy: 0.7980 - val_loss: 0.6516 - val_accuracy: 0.7754\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5614 - accuracy: 0.8025 - val_loss: 0.6805 - val_accuracy: 0.7758\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5424 - accuracy: 0.8098 - val_loss: 0.6425 - val_accuracy: 0.7806\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5268 - accuracy: 0.8150 - val_loss: 0.6217 - val_accuracy: 0.7938\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5254 - accuracy: 0.8167 - val_loss: 0.6474 - val_accuracy: 0.7835\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5121 - accuracy: 0.8185 - val_loss: 0.6538 - val_accuracy: 0.7808\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 0.5092 - accuracy: 0.8207 - val_loss: 0.6505 - val_accuracy: 0.7830\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.4918 - accuracy: 0.8268 - val_loss: 0.6696 - val_accuracy: 0.7825\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.4821 - accuracy: 0.8306 - val_loss: 0.6539 - val_accuracy: 0.7845\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4736 - accuracy: 0.8327 - val_loss: 0.6686 - val_accuracy: 0.7864\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.4683 - accuracy: 0.8361 - val_loss: 0.6973 - val_accuracy: 0.7816\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.4615 - accuracy: 0.8395 - val_loss: 0.6752 - val_accuracy: 0.7839\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4488 - accuracy: 0.8415 - val_loss: 0.6498 - val_accuracy: 0.7864\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4497 - accuracy: 0.8419 - val_loss: 0.6646 - val_accuracy: 0.7918\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4384 - accuracy: 0.8473 - val_loss: 0.6691 - val_accuracy: 0.7887\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 0.4323 - accuracy: 0.8501 - val_loss: 0.6624 - val_accuracy: 0.7873\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4289 - accuracy: 0.8497 - val_loss: 0.6850 - val_accuracy: 0.7794\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.4248 - accuracy: 0.8525 - val_loss: 0.6811 - val_accuracy: 0.7881\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x_train, \n",
    "    y_train,\n",
    "    batch_size = 32,\n",
    "    epochs = 30,\n",
    "    validation_data = (x_test, y_test),\n",
    "    shuffle = True,\n",
    "    callbacks = [callback]    \n",
    ")\n",
    "\n",
    "# Save neural network sturcture\n",
    "model_structure = model.to_json()\n",
    "f = Path('modlel_structure.json')\n",
    "f.write_text(model_structure)\n",
    "\n",
    "# Save neural network trained weights\n",
    "model.save_weights('model_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\n",
    "    'Plane',\n",
    "    'Car',\n",
    "    'Bird',\n",
    "    'Cat',\n",
    "    'Deer',\n",
    "    'Dog',\n",
    "    'Frog',\n",
    "    'Horse',\n",
    "    'Boat',\n",
    "    'Truck'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Neural Network structure\n",
    "f = Path('modlel_structure.json')\n",
    "model_structure = f.read_text()\n",
    "\n",
    "# Recreate the Neural Network\n",
    "model = tf.keras.models.model_from_json(model_structure)\n",
    "\n",
    "# Reload the models trained weights\n",
    "model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load an image to test with (resize to 32x32 pixels)\n",
    "img = image.load_img('dodger.jpg', target_size=(32,32))\n",
    "\n",
    "# Convert image to numpy array\n",
    "image_to_test = image.img_to_array(img) / 255 # Scale image from 0 to 1\n",
    "\n",
    "# Create a Batch of images as a 4D array\n",
    "list_of_images = np.expand_dims(image_to_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image is a Car - Likelihood: 0.7175264954566956\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using the model\n",
    "results = model.predict(list_of_images)\n",
    "\n",
    "# Since we only tested one image, we only need to check the first result\n",
    "single_result = results[0]\n",
    "\n",
    "# Get the likelihood of all possible classes\n",
    "most_like_class_index = int(np.argmax(single_result))\n",
    "class_likelihood = single_result[most_like_class_index]\n",
    "\n",
    "# Get the name of the most likely class\n",
    "class_label = class_labels[most_like_class_index]\n",
    "\n",
    "# Print the result\n",
    "print(f'This image is a {class_label} - Likelihood: {class_likelihood}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Deep_Learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "096db544af28c78b77f99f5b558907d77c58cb7acc42aa3ed5e25e2771f11f9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
